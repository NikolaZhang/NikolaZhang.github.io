---
isOriginal: false
title: 日志
date: 2021-05-22
tag:
  - 爬虫
  - scrapy
  - 日志
category: scrapy
description: scrapy中如何使用日志
image: http://image.nikolazhang.top/wallhaven-nrwq11.jpg
---


> Scrapy提供了log功能。您可以通过 scrapy.log 模块使用。当前底层实现使用了 Twisted logging ，不过可能在之后会有所变化。

log服务必须通过显示调用 `scrapy.log.start()` 来开启，以捕捉顶层的Scrapy日志消息。 在此之上，每个crawler都拥有独立的log观察者(observer)(创建时自动连接(attach)),接收其spider的日志消息。

## 日志级别

1. **`[CRITICAL](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.CRITICAL)`** - 严重错误(critical)
2. **`[ERROR](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.ERROR)`** - 一般错误(regular errors)
3. **`[WARNING](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.WARNING)`** - 警告信息(warning messages)
4. **`[INFO](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.INFO)`** - 一般信息(informational messages)
5. **`[DEBUG](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.DEBUG)`** - 调试信息(debugging messages)

### 如何设置日志级别

您可以通过终端选项(command line option) –loglevel/-L 或 LOG_LEVEL 来设置log级别。

### 如何记录信息

```python
from scrapy import log
log.msg("This is a warning", level=log.WARNING)
```

## **scrapy.log模块**

> **`scrapy.log.start`(*logfile=None*, *loglevel=None*, *logstdout=None*)**

启动Scrapy顶层logger。该方法必须在记录任何顶层消息前被调用 (使用模块的 **`[msg()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.msg)`** 而不是 **`[Spider.log](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.log)`** 的消息)。否则，之前的消息将会丢失。

参数:

• **logfile** (*str*) – 用于保存log输出的文件路径。如果被忽略， **`[LOG_FILE](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-LOG_FILE)`** 设置会被使用。 如果两个参数都是 **`None`** ，log将会被输出到标准错误流(standard error)。
• **loglevel** – 记录的最低的log级别. 可用的值有: **`[CRITICAL](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.CRITICAL)`**, **`[ERROR](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.ERROR)`**, **`[WARNING](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.WARNING)`**, **`[INFO](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.INFO)`** and **`[DEBUG](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.DEBUG)`**.
• **logstdout** (*boolean*) – 如果为 **`True`** ， 所有您的应用的标准输出(包括错误)将会被记录(logged instead)。 例如，如果您调用 “print ‘hello’” ，则’hello’ 会在Scrapy的log中被显示。 如果被忽略，则 **`[LOG_STDOUT](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-LOG_STDOUT)`** 设置会被使用。

> **`scrapy.log.msg`(*message*, *level=INFO*, *spider=None*)**

记录信息(Log a message)

参数:

• **message** (*str*) – log的信息
• **level** – 该信息的log级别. 参考 [Log levels](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#topics-logging-levels).
• **spider** (**`[Spider](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider)`** 对象) – 记录该信息的spider. 当记录的信息和特定的spider有关联时，该参数必须被使用。

## **Logging设置**

以下设置可以被用来配置logging:

- **`[LOG_ENABLED](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-LOG_ENABLED)`**
- **`[LOG_ENCODING](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-LOG_ENCODING)`**
- **`[LOG_FILE](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-LOG_FILE)`**
- **`[LOG_LEVEL](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-LOG_LEVEL)`**
- **`[LOG_STDOUT](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#std:setting-LOG_STDOUT)`**