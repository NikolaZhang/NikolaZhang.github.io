const e=JSON.parse('{"key":"v-3b220d19","path":"/posts/scrapy/Item%20Pipeline.html","title":"Item Pipeline","lang":"en-US","frontmatter":{"isOriginal":false,"title":"Item Pipeline","date":"2021-05-17T00:00:00.000Z","tag":["爬虫","scrapy","Pipeline"],"category":"scrapy","description":"scrapy中使用管道处理item","image":"http://image.nikolazhang.top/wallhaven-nrwq11.jpg","sticky":false,"timeline":true,"article":true,"star":false,"head":[["meta",{"property":"og:url","content":"https://nikolazhang.github.io/posts/scrapy/Item%20Pipeline.html"}],["meta",{"property":"og:title","content":"Item Pipeline"}],["meta",{"property":"og:description","content":"scrapy中使用管道处理item"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2023-06-08T15:09:36.000Z"}],["meta",{"property":"article:author","content":"我小叮当、"}],["meta",{"property":"article:tag","content":"爬虫"}],["meta",{"property":"article:tag","content":"scrapy"}],["meta",{"property":"article:tag","content":"Pipeline"}],["meta",{"property":"article:published_time","content":"2021-05-17T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-06-08T15:09:36.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Item Pipeline\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2021-05-17T00:00:00.000Z\\",\\"dateModified\\":\\"2023-06-08T15:09:36.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"我小叮当、\\",\\"url\\":\\"https://nikolazhang.github.io\\"}]}"]]},"headers":[{"level":2,"title":"编写你自己的item pipeline¶","slug":"编写你自己的item-pipeline¶","link":"#编写你自己的item-pipeline¶","children":[]},{"level":2,"title":"案例","slug":"案例","link":"#案例","children":[{"level":3,"title":"验证，同时丢弃","slug":"验证-同时丢弃","link":"#验证-同时丢弃","children":[]},{"level":3,"title":"写入json","slug":"写入json","link":"#写入json","children":[]},{"level":3,"title":"写入MongoDB","slug":"写入mongodb","link":"#写入mongodb","children":[]},{"level":3,"title":"去重","slug":"去重","link":"#去重","children":[]}]},{"level":2,"title":"启用一个Item Pipeline组件","slug":"启用一个item-pipeline组件","link":"#启用一个item-pipeline组件","children":[]}],"git":{"createdTime":1686236976000,"updatedTime":1686236976000,"contributors":[{"name":"nikola","email":"nikolazhang@163.com","commits":1}]},"readingTime":{"minutes":2.8,"words":841},"filePathRelative":"posts/scrapy/Item Pipeline.md","localizedDate":"May 17, 2021","excerpt":"<blockquote>\\n<p>当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理。</p>\\n</blockquote>\\n<p>每个item pipeline组件(有时称之为“Item Pipeline”)是实现了简单方法的Python类。他们接收到Item并通过它执行一些行为，同时也决定此Item是否继续通过pipeline，或是被丢弃而不再进行处理。</p>\\n<p>以下是item pipeline的一些典型应用：</p>\\n<ul>\\n<li>清理HTML数据</li>\\n<li>验证爬取的数据(检查item包含某些字段)</li>\\n<li>查重(并丢弃)</li>\\n<li>将爬取结果保存到数据库中</li>\\n</ul>"}');export{e as data};
