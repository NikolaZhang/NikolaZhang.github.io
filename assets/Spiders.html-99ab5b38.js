import{_ as p}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as c,c as r,a as s,b as n,d as a,e as t}from"./app-d92b3f51.js";const i={},l={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html",target:"_blank",rel:"noopener noreferrer"},d=s("blockquote",null,[s("p",null,"Spider类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。 换句话说，Spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。")],-1),u=s("p",null,"对spider来说，爬取的循环类似下文:",-1),h=t("<li><p>以初始的URL初始化Request，并设置回调函数。 当该request下载完毕并返回时，将生成response，并作为参数传给该回调函数。</p><p>spider中初始的request是通过调用 <code>[start_requests()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.start_requests)</code> 来获取的。 <code>[start_requests()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.start_requests)</code> 读取 <code>[start_urls](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.start_urls)</code> 中的URL， 并以 <code>[parse](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.parse)</code> 为回调函数生成 <code>[Request](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#scrapy.http.Request)</code> 。</p></li><li><p>在回调函数内分析返回的(网页)内容，返回 <code>[Item](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/items.html#scrapy.item.Item)</code> 对象或者 <code>[Request](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#scrapy.http.Request)</code> 或者一个包括二者的可迭代容器。 返回的Request对象之后会经过Scrapy处理，下载相应的内容，并调用设置的callback函数(函数可相同)。</p></li>",2),k={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/selectors.html#topics-selectors",target:"_blank",rel:"noopener noreferrer"},m={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/item-pipeline.html#topics-item-pipeline",target:"_blank",rel:"noopener noreferrer"},_={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/feed-exports.html#topics-feed-exports",target:"_blank",rel:"noopener noreferrer"},v=s("p",null,"虽然该循环对任何类型的spider都(多少)适用，但Scrapy仍然为了不同的需求提供了多种默认spider。 之后将讨论这些spider。",-1),b={id:"spider参数¶",tabindex:"-1"},y=s("a",{class:"header-anchor",href:"#spider参数¶","aria-hidden":"true"},"#",-1),g={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#spider",target:"_blank",rel:"noopener noreferrer"},f=t(`<p>Spider可以通过接受参数来修改其功能。 spider参数一般用来定义初始URL或者指定限制爬取网站的部分。 您也可以使用其来配置spider的任何功能。</p><p>在运行 <code>[crawl](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/commands.html#std:command-crawl)</code> 时添加 <code>-a</code> 可以传递Spider参数:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>scrapy crawl myspider <span class="token parameter variable">-a</span> <span class="token assign-left variable">category</span><span class="token operator">=</span>electronics
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>Spider在构造器(constructor)中获取参数:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
name <span class="token operator">=</span> <span class="token string">&#39;myspider&#39;</span>

<span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> category<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>MySpider<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;&lt;http://www.example.com/categories/%s&gt;&#39;</span> <span class="token operator">%</span> category<span class="token punctuation">]</span>
    <span class="token comment"># ...</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,5),w=s("code",null,"schedule.json",-1),S={href:"http://scrapyd.readthedocs.org/",target:"_blank",rel:"noopener noreferrer"},C={id:"内置spider参考手册¶",tabindex:"-1"},x=s("a",{class:"header-anchor",href:"#内置spider参考手册¶","aria-hidden":"true"},"#",-1),N={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#topics-spiders-ref",target:"_blank",rel:"noopener noreferrer"},q={href:"http://www.sitemaps.org/",target:"_blank",rel:"noopener noreferrer"},z=t(`<p>下面spider的示例中，我们假定您有个项目在 <code>myproject.items</code> 模块中声明了 <code>TestItem</code>:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">TestItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token builtin">id</span> <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
		name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
		description <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,2),R={id:"_1-spider¶",tabindex:"-1"},M=s("a",{class:"header-anchor",href:"#_1-spider¶","aria-hidden":"true"},"#",-1),L={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#id2",target:"_blank",rel:"noopener noreferrer"},F=s("em",null,"class",-1),I=s("code",null,"scrapy.spider.Spider",-1),X={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider",target:"_blank",rel:"noopener noreferrer"},V=s("p",null,[n("Spider是最简单的spider。每个其他的spider必须继承自该类(包括Scrapy自带的其他spider以及您自己编写的spider)。 Spider并没有提供什么特殊的功能。 其仅仅请求给定的 "),s("code",null,"start_urls"),n("/"),s("code",null,"start_requests"),n(" ，并根据返回的结果(resulting responses)调用spider的 "),s("code",null,"parse"),n(" 方法。")],-1),T=s("code",null,"name",-1),U={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.name",target:"_blank",rel:"noopener noreferrer"},j=s("p",null,"定义spider名字的字符串(string)。spider的名字定义了Scrapy如何定位(并初始化)spider，所以其必须是唯一的。 不过您可以生成多个相同的spider实例(instance)，这没有任何限制。 name是spider最重要的属性，而且是必须的。",-1),D={href:"http://en.wikipedia.org/wiki/Top-level_domain",target:"_blank",rel:"noopener noreferrer"},O=s("code",null,"mywebsite.com",-1),E=s("code",null,"mywebsite",-1),A=s("code",null,"allowed_domains",-1),P={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.allowed_domains",target:"_blank",rel:"noopener noreferrer"},B=s("p",null,[n("可选。包含了spider允许爬取的域名(domain)列表(list)。 当 "),s("code",null,"[OffsiteMiddleware](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spider-middleware.html#scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware)"),n(" 启用时， 域名不在列表中的URL不会被跟进。")],-1),H=s("code",null,"start_urls",-1),Y={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.start_urls",target:"_blank",rel:"noopener noreferrer"},G=s("p",null,"URL列表。当没有制定特定的URL时，spider将从该列表中开始进行爬取。 因此，第一个被获取到的页面的URL将是该列表之一。 后续的URL将会从获取到的数据中提取。",-1),J=s("code",null,"custom_settings",-1),K={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.custom_settings",target:"_blank",rel:"noopener noreferrer"},Q=s("p",null,"A dictionary of settings that will be overridden from the project wide configuration when running this spider. It must be defined as a class attribute since the settings are updated before instantiation.",-1),W={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#topics-settings-ref",target:"_blank",rel:"noopener noreferrer"},Z=s("code",null,"crawler",-1),$={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.crawler",target:"_blank",rel:"noopener noreferrer"},ss=s("p",null,[n("This attribute is set by the "),s("code",null,"[from_crawler()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/item-pipeline.html#from_crawler)"),n(" class method after initializating the class, and links to the "),s("code",null,"[Crawler](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/api.html#scrapy.crawler.Crawler)"),n(" object to which this spider instance is bound.")],-1),ns={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/api.html#topics-api-crawler",target:"_blank",rel:"noopener noreferrer"},es=s("code",null,"settings",-1),as={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.settings",target:"_blank",rel:"noopener noreferrer"},ts=s("code",null,"[Settings](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/api.html#scrapy.settings.Settings)",-1),ps={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/settings.html#topics-settings",target:"_blank",rel:"noopener noreferrer"},os=s("code",null,"from_crawler",-1),cs=s("em",null,"crawler",-1),rs=s("em",null,"args",-1),is=s("em",null,"kwargs",-1),ls={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.from_crawler",target:"_blank",rel:"noopener noreferrer"},ds=s("p",null,"This is the class method used by Scrapy to create your spiders.",-1),us=s("p",null,[n("You probably won’t need to override this directly, since the default implementation acts as a proxy to the "),s("code",null,"__init__()"),n(" method, calling it with the given arguments args and named arguments kwargs.")],-1),hs=s("p",null,[n("Nonetheless, this method sets the "),s("code",null,"[crawler](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.crawler)"),n(" and "),s("code",null,"[settings](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.settings)"),n(" attributes in the new instance, so they can be accessed later inside the spider’s code.")],-1),ks=s("p",null,"参数:",-1),ms=s("li",null,[s("strong",null,"crawler"),n(" ("),s("code",null,"[Crawler](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/api.html#scrapy.crawler.Crawler)"),n(" instance) – crawler to which the spider will be bound")],-1),_s=s("strong",null,"args",-1),vs={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/api.html#scrapy.spidermanager.SpiderManager.list",target:"_blank",rel:"noopener noreferrer"},bs=s("code",null,"__init__()",-1),ys=s("li",null,[s("strong",null,"kwargs"),n(" ("),s("em",null,"dict"),n(") – keyword arguments passed to the "),s("code",null,"__init__()"),n(" method")],-1),gs=s("code",null,"start_requests",-1),fs={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.start_requests",target:"_blank",rel:"noopener noreferrer"},ws=t(`<p>该方法必须返回一个可迭代对象(iterable)。该对象包含了spider用于爬取的第一个Request。</p><p>当spider启动爬取并且未制定URL时，该方法被调用。 当指定了URL时，<code>[make_requests_from_url()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.make_requests_from_url)</code> 将被调用来创建Request对象。 该方法仅仅会被Scrapy调用一次，因此您可以将其实现为生成器。</p><p>该方法的默认实现是使用 <code>[start_urls](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.start_urls)</code> 的url生成Request。</p><p>如果您想要修改<code>最初爬取某个网站的Request对象</code>，您可以重写(override)该方法。 例如，如果您需要在启动时以POST登录某个网站，你可以这么写:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>scrapy<span class="token punctuation">.</span>FormRequest<span class="token punctuation">(</span><span class="token string">&quot;http://www.example.com/login&quot;</span><span class="token punctuation">,</span>
                               formdata<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">&#39;user&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;john&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;pass&#39;</span><span class="token punctuation">:</span> <span class="token string">&#39;secret&#39;</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                               callback<span class="token operator">=</span>self<span class="token punctuation">.</span>logged_in<span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">logged_in</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># here you would extract links to follow and return Requests for</span>
    <span class="token comment"># each of them, with another callback</span>
    <span class="token keyword">pass</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,5),Ss=s("code",null,"make_requests_from_url",-1),Cs=s("em",null,"url",-1),xs={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.make_requests_from_url",target:"_blank",rel:"noopener noreferrer"},Ns=s("p",null,[n("该方法接受一个URL并返回用于爬取的 "),s("code",null,"[Request](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#scrapy.http.Request)"),n(" 对象。 该方法在初始化request时被 "),s("code",null,"[start_requests()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.start_requests)"),n(" 调用，也被用于转化url为request。")],-1),qs=s("p",null,[n("默认未被复写(overridden)的情况下，该方法返回的Request对象中， "),s("code",null,"[parse()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.parse)"),n(" 作为回调函数，dont_filter参数也被设置为开启。 (详情参见 "),s("code",null,"[Request](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#scrapy.http.Request)"),n(").")],-1),zs=s("code",null,"parse",-1),Rs=s("em",null,"response",-1),Ms={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.parse",target:"_blank",rel:"noopener noreferrer"},Ls=t("<p>当response没有指定回调函数时，该方法是Scrapy处理下载的response的默认方法。</p><p><code>parse</code> 负责处理response并返回处理的数据以及(/或)跟进的URL。 <code>[Spider](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider)</code> 对其他的Request的回调函数也有相同的要求。</p><p>该方法及其他的Request回调函数必须返回一个包含 <code>[Request](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#scrapy.http.Request)</code> 及(或) <code>[Item](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/items.html#scrapy.item.Item)</code> 的可迭代的对象。</p><p>参数:</p><p><strong>response</strong> (<code>[Response](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#scrapy.http.Response)</code>) – 用于分析的response</p>",5),Fs=s("code",null,"log",-1),Is=s("em",null,"message",-1),Xs=s("em",null,"level",-1),Vs=s("em",null,"component",-1),Ts={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.log",target:"_blank",rel:"noopener noreferrer"},Us=s("code",null,"[scrapy.log.msg()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#scrapy.log.msg)",-1),js=s("code",null,"[name](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.name)",-1),Ds={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/logging.html#topics-logging",target:"_blank",rel:"noopener noreferrer"},Os=s("code",null,"closed",-1),Es=s("em",null,"reason",-1),As={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.spider.Spider.closed",target:"_blank",rel:"noopener noreferrer"},Ps=s("p",null,[n("当spider关闭时，该函数被调用。 该方法提供了一个替代调用signals.connect()来监听 "),s("code",null,"[spider_closed](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/signals.html#std:signal-spider_closed)"),n(" 信号的快捷方式。")],-1),Bs={id:"spider样例¶",tabindex:"-1"},Hs=s("a",{class:"header-anchor",href:"#spider样例¶","aria-hidden":"true"},"#",-1),Ys={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#id3",target:"_blank",rel:"noopener noreferrer"},Gs=t(`<p>让我们来看一个例子:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&#39;example.com&#39;</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;example.com&#39;</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string">&#39;http://www.example.com/1.html&#39;</span><span class="token punctuation">,</span>
        <span class="token string">&#39;http://www.example.com/2.html&#39;</span><span class="token punctuation">,</span>
        <span class="token string">&#39;http://www.example.com/3.html&#39;</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">&#39;A response from %s just arrived!&#39;</span> <span class="token operator">%</span> response<span class="token punctuation">.</span>url<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>另一个在单个回调函数中返回多个Request以及Item的例子:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> myproject<span class="token punctuation">.</span>items <span class="token keyword">import</span> MyItem

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&#39;example.com&#39;</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;example.com&#39;</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string">&#39;http://www.example.com/1.html&#39;</span><span class="token punctuation">,</span>
        <span class="token string">&#39;http://www.example.com/2.html&#39;</span><span class="token punctuation">,</span>
        <span class="token string">&#39;http://www.example.com/3.html&#39;</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sel <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Selector<span class="token punctuation">(</span>response<span class="token punctuation">)</span>
        <span class="token keyword">for</span> h3 <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//h3&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> MyItem<span class="token punctuation">(</span>title<span class="token operator">=</span>h3<span class="token punctuation">)</span>

        <span class="token keyword">for</span> url <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//a/@href&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4),Js={id:"_2-crawlspider¶",tabindex:"-1"},Ks=s("a",{class:"header-anchor",href:"#_2-crawlspider¶","aria-hidden":"true"},"#",-1),Qs={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#crawlspider",target:"_blank",rel:"noopener noreferrer"},Ws=s("em",null,"class",-1),Zs=s("code",null,"scrapy.contrib.spiders.CrawlSpider",-1),$s={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CrawlSpider",target:"_blank",rel:"noopener noreferrer"},sn=s("p",null,[n("爬取一般网站常用的spider。其"),s("code",null,"定义了一些规则(rule)来提供跟进link"),n("的方便的机制。 也许该spider并不是完全适合您的特定网站或项目，但其对很多情况都使用。 因此您可以以其为起点，根据需求修改部分方法。当然您也可以实现自己的spider。")],-1),nn=s("p",null,"除了从Spider继承过来的(您必须提供的)属性外，其提供了一个新的属性:",-1),en=s("code",null,"rules",-1),an={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CrawlSpider.rules",target:"_blank",rel:"noopener noreferrer"},tn=s("p",null,[n("一个包含一个(或多个) "),s("code",null,"[Rule](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.Rule)"),n(" 对象的集合(list)。 每个 "),s("code",null,"[Rule](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.Rule)"),n(" 对爬取网站的动作定义了特定表现。 Rule对象在下边会介绍。 如果多个rule匹配了相同的链接，则根据他们在本属性中被定义的顺序，第一个会被使用。")],-1),pn=s("p",null,"该spider也提供了一个可复写(overrideable)的方法:",-1),on=s("code",null,"parse_start_url",-1),cn=s("em",null,"response",-1),rn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CrawlSpider.parse_start_url",target:"_blank",rel:"noopener noreferrer"},ln=s("p",null,[n("当start_url的请求返回时，该方法被调用。 该方法分析最初的返回值并必须返回一个 "),s("code",null,"[Item](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/items.html#scrapy.item.Item)"),n(" 对象或者 一个 "),s("code",null,"[Request](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#scrapy.http.Request)"),n(" 对象或者 一个可迭代的包含二者对象。")],-1),dn={id:"爬取规则-crawling-rules-¶",tabindex:"-1"},un=s("a",{class:"header-anchor",href:"#爬取规则-crawling-rules-¶","aria-hidden":"true"},"#",-1),hn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#crawling-rules",target:"_blank",rel:"noopener noreferrer"},kn=s("em",null,"class",-1),mn=s("code",null,"scrapy.contrib.spiders.Rule",-1),_n=s("em",null,"extractor",-1),vn=s("em",null,"callback=None",-1),bn=s("em",null,"kwargs=None",-1),yn=s("em",null,"follow=None",-1),gn=s("em",null,"links=None",-1),fn=s("em",null,"request=None",-1),wn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.Rule",target:"_blank",rel:"noopener noreferrer"},Sn=s("code",null,"link_extractor",-1),Cn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/link-extractors.html#topics-link-extractors",target:"_blank",rel:"noopener noreferrer"},xn=t("<p><code>callback</code> 是一个callable或string(该spider中同名的函数将会被调用)。 从link_extractor中每获取到链接时将会调用该函数。该回调函数接受一个response作为其第一个参数， 并返回一个包含 <code>[Item](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/items.html#scrapy.item.Item)</code> 以及(或) <code>[Request](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#scrapy.http.Request)</code> 对象(或者这两者的子类)的列表(list)。</p><p>警告</p><p>当编写爬虫规则时，请避免使用 <code>parse</code> 作为回调函数。 由于 <code>[CrawlSpider](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CrawlSpider)</code> 使用 <code>parse</code> 方法来实现其逻辑，如果 您覆盖了 <code>parse</code> 方法，crawl spider 将会运行失败。</p><p><code>cb_kwargs</code> 包含传递给回调函数的参数(keyword argument)的字典。</p><p><code>follow</code> 是一个布尔(boolean)值，指定了根据该规则从response提取的链接是否需要跟进。 如果 <code>callback</code> 为None， <code>follow</code> 默认设置为 <code>True</code> ，否则默认为 <code>False</code> 。</p><p><code>process_links</code> 是一个callable或string(该spider中同名的函数将会被调用)。 从link_extractor中获取到链接列表时将会调用该函数。该方法主要用来过滤。</p><p><code>process_request</code> 是一个callable或string(该spider中同名的函数将会被调用)。 该规则提取到每个request时都会调用该函数。该函数必须返回一个request或者None。 (用来过滤request)</p>",7),Nn={id:"crawlspider样例¶",tabindex:"-1"},qn=s("a",{class:"header-anchor",href:"#crawlspider样例¶","aria-hidden":"true"},"#",-1),zn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#id4",target:"_blank",rel:"noopener noreferrer"},Rn=t(`<p>接下来给出配合rule使用CrawlSpider的例子:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&#39;example.com&#39;</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;example.com&#39;</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;http://www.example.com&#39;</span><span class="token punctuation">]</span>

    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
        <span class="token comment"># 提取匹配 &#39;category.php&#39; (但不匹配 &#39;subsection.php&#39;) 的链接并跟进链接(没有callback意味着follow默认为True)</span>
        Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">&#39;category\\.php&#39;</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">,</span> deny<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">&#39;subsection\\.php&#39;</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>

        <span class="token comment"># 提取匹配 &#39;item.php&#39; 的链接并使用spider的parse_item方法进行分析</span>
        Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">&#39;item\\.php&#39;</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">&#39;parse_item&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token string">&#39;Hi, this is an item page! %s&#39;</span> <span class="token operator">%</span> response<span class="token punctuation">.</span>url<span class="token punctuation">)</span>

        item <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;id&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//td[@id=&quot;item_id&quot;]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>re<span class="token punctuation">(</span><span class="token string">r&#39;ID: (\\d+)&#39;</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;name&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//td[@id=&quot;item_name&quot;]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;description&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//td[@id=&quot;item_description&quot;]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>该spider将从example.com的首页开始爬取，获取category以及item的链接并对后者使用 <code>parse_item</code> 方法。 当item获得返回(response)时，将使用XPath处理HTML并生成一些数据填入 <code>[Item](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/items.html#scrapy.item.Item)</code> 中。</p>`,3),Mn={id:"_3-xmlfeedspider¶",tabindex:"-1"},Ln=s("a",{class:"header-anchor",href:"#_3-xmlfeedspider¶","aria-hidden":"true"},"#",-1),Fn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#xmlfeedspider",target:"_blank",rel:"noopener noreferrer"},In=s("em",null,"class",-1),Xn=s("code",null,"scrapy.contrib.spiders.XMLFeedSpider",-1),Vn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.XMLFeedSpider",target:"_blank",rel:"noopener noreferrer"},Tn=t("<p>XMLFeedSpider被设计用于通过迭代各个节点来分析XML源(XML feed)。 迭代器可以从 <code>iternodes</code> ， <code>xml</code> ， <code>html</code> 选择。 鉴于 <code>xml</code> 以及 <code>html</code> 迭代器需要先读取所有DOM再分析而引起的性能问题， 一般还是推荐使用 <code>iternodes</code> 。 不过使用 <code>html</code> 作为迭代器能有效应对错误的XML。</p><p>您必须定义下列类属性来设置迭代器以及标签名(tag name):</p>",2),Un=s("code",null,"iterator",-1),jn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.XMLFeedSpider.iterator",target:"_blank",rel:"noopener noreferrer"},Dn=t("<p>用于确定使用哪个迭代器的string。可选项有:</p><ul><li><strong><code>&#39;iternodes&#39;</code></strong> - 一个高性能的基于正则表达式的迭代器, 默认值</li><li><strong><code>&#39;html&#39;</code></strong> - 使用 <strong><code>[Selector](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/selectors.html#scrapy.selector.Selector)</code></strong> 的迭代器。 需要注意的是该迭代器使用DOM进行分析，其需要将所有的DOM载入内存， 当数据量大的时候会产生问题。</li><li><strong><code>&#39;xml&#39;</code></strong> - 使用 <strong><code>[Selector](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/selectors.html#scrapy.selector.Selector)</code></strong> 的迭代器。 需要注意的是该迭代器使用DOM进行分析，其需要将所有的DOM载入内存， 当数据量大的时候会产生问题。</li></ul>",2),On=s("code",null,"itertag",-1),En={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.XMLFeedSpider.itertag",target:"_blank",rel:"noopener noreferrer"},An=t(`<p>一个包含开始迭代的节点名的string。例如:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>itertag <span class="token operator">=</span> <span class="token string">&#39;product&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,2),Pn=s("code",null,"namespaces",-1),Bn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.XMLFeedSpider.namespaces",target:"_blank",rel:"noopener noreferrer"},Hn=t(`<p>一个由 <code>(prefix, url)</code> 元组(tuple)所组成的list。 其定义了在该文档中会被spider处理的可用的namespace。 <code>prefix</code> 及 <code>uri</code> 会被自动调用 <code>[register_namespace()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/selectors.html#scrapy.selector.Selector.register_namespace)</code> 生成namespace。</p><p>您可以通过在 <code>[itertag](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.XMLFeedSpider.itertag)</code> 属性中制定节点的namespace。</p><p>例如:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">YourSpider</span><span class="token punctuation">(</span>XMLFeedSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>

    namespaces <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">&#39;n&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;http://www.sitemaps.org/schemas/sitemap/0.9&#39;</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    itertag <span class="token operator">=</span> <span class="token string">&#39;n:url&#39;</span>
    <span class="token comment"># ...</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>除了这些新的属性之外，该spider也有以下可以覆盖(overrideable)的方法:</p>`,5),Yn=s("code",null,"adapt_response",-1),Gn=s("em",null,"response",-1),Jn={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.XMLFeedSpider.adapt_response",target:"_blank",rel:"noopener noreferrer"},Kn=s("p",null,"该方法在spider分析response前被调用。您可以在response被分析之前使用该函数来修改内容(body)。 该方法接受一个response并返回一个response(可以相同也可以不同)。",-1),Qn=s("code",null,"parse_node",-1),Wn=s("em",null,"response",-1),Zn=s("em",null,"selector",-1),$n={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.XMLFeedSpider.parse_node",target:"_blank",rel:"noopener noreferrer"},se=s("p",null,[n("当节点符合提供的标签名时("),s("code",null,"itertag"),n(")该方法被调用。 接收到的response以及相应的 "),s("code",null,"[Selector](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/selectors.html#scrapy.selector.Selector)"),n(" 作为参数传递给该方法。 该方法返回一个 "),s("code",null,"[Item](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/items.html#scrapy.item.Item)"),n(" 对象或者 "),s("code",null,"[Request](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/request-response.html#scrapy.http.Request)"),n(" 对象 或者一个包含二者的可迭代对象(iterable)。")],-1),ne=s("code",null,"process_results",-1),ee=s("em",null,"response",-1),ae=s("em",null,"results",-1),te={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.XMLFeedSpider.process_results",target:"_blank",rel:"noopener noreferrer"},pe=s("p",null,"当spider返回结果(item或request)时该方法被调用。 设定该方法的目的是在结果返回给框架核心(framework core)之前做最后的处理， 例如设定item的ID。其接受一个结果的列表(list of results)及对应的response。 其结果必须返回一个结果的列表(list of results)(包含Item或者Request对象)。",-1),oe={id:"xmlfeedspider例子¶",tabindex:"-1"},ce=s("a",{class:"header-anchor",href:"#xmlfeedspider例子¶","aria-hidden":"true"},"#",-1),re={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#id5",target:"_blank",rel:"noopener noreferrer"},ie=t(`<p>该spider十分易用。下边是其中一个例子:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> log
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> XMLFeedSpider
<span class="token keyword">from</span> myproject<span class="token punctuation">.</span>items <span class="token keyword">import</span> TestItem

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>XMLFeedSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&#39;example.com&#39;</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;example.com&#39;</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;http://www.example.com/feed.xml&#39;</span><span class="token punctuation">]</span>
    iterator <span class="token operator">=</span> <span class="token string">&#39;iternodes&#39;</span> <span class="token comment"># This is actually unnecessary, since it&#39;s the default value</span>
    itertag <span class="token operator">=</span> <span class="token string">&#39;item&#39;</span>

    <span class="token keyword">def</span> <span class="token function">parse_node</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> node<span class="token punctuation">)</span><span class="token punctuation">:</span>
        log<span class="token punctuation">.</span>msg<span class="token punctuation">(</span><span class="token string">&#39;Hi, this is a &lt;%s&gt; node!: %s&#39;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>itertag<span class="token punctuation">,</span> <span class="token string">&#39;&#39;</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>node<span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        item <span class="token operator">=</span> TestItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;id&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;@id&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;name&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;name&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;description&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;description&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>简单来说，我们在这里创建了一个spider，从给定的 <code>start_urls</code> 中下载feed， 并迭代feed中每个 <code>item</code> 标签，输出，并在 <code>[Item](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/items.html#scrapy.item.Item)</code> 中存储有些随机数据。</p>`,3),le={id:"_4-csvfeedspider¶",tabindex:"-1"},de=s("a",{class:"header-anchor",href:"#_4-csvfeedspider¶","aria-hidden":"true"},"#",-1),ue={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#csvfeedspider",target:"_blank",rel:"noopener noreferrer"},he=s("em",null,"class",-1),ke=s("code",null,"scrapy.contrib.spiders.CSVFeedSpider",-1),me={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CSVFeedSpider",target:"_blank",rel:"noopener noreferrer"},_e=s("p",null,[n("该spider除了其按行遍历而不是节点之外其他和XMLFeedSpider十分类似。 而其在每次迭代时调用的是 "),s("code",null,"[parse_row()](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CSVFeedSpider.parse_row)"),n(" 。")],-1),ve=s("code",null,"delimiter",-1),be={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CSVFeedSpider.delimiter",target:"_blank",rel:"noopener noreferrer"},ye=s("p",null,[n("在CSV文件中用于区分字段的分隔符。类型为string。 默认为 "),s("code",null,"','"),n(" (逗号)。")],-1),ge=s("code",null,"quotechar",-1),fe={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CSVFeedSpider.quotechar",target:"_blank",rel:"noopener noreferrer"},we=s("p",null,[n("A string with the enclosure character for each field in the CSV file Defaults to "),s("code",null,`'"'`),n(" (quotation mark).")],-1),Se=s("p",null,"在CSV文件中包含的用来提取字段的行的列表。参考下边的例子。",-1),Ce=s("code",null,"parse_row",-1),xe=s("em",null,"response",-1),Ne=s("em",null,"row",-1),qe={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CSVFeedSpider.parse_row",target:"_blank",rel:"noopener noreferrer"},ze=s("p",null,[n("该方法接收一个response对象及一个以提供或检测出来的header为键的字典(代表每行)。 该spider中，您也可以覆盖 "),s("code",null,"adapt_response"),n(" 及 "),s("code",null,"process_results"),n(" 方法来进行预处理(pre-processing)及后(post-processing)处理。")],-1),Re={id:"csvfeedspider例子¶",tabindex:"-1"},Me=s("a",{class:"header-anchor",href:"#csvfeedspider例子¶","aria-hidden":"true"},"#",-1),Le={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#id6",target:"_blank",rel:"noopener noreferrer"},Fe=t(`<p>下面的例子和之前的例子很像，但使用了 <code>[CSVFeedSpider](https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.CSVFeedSpider)</code>:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> log
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CSVFeedSpider
<span class="token keyword">from</span> myproject<span class="token punctuation">.</span>items <span class="token keyword">import</span> TestItem

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>CSVFeedSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&#39;example.com&#39;</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;example.com&#39;</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;http://www.example.com/feed.csv&#39;</span><span class="token punctuation">]</span>
    delimiter <span class="token operator">=</span> <span class="token string">&#39;;&#39;</span>
    quotechar <span class="token operator">=</span> <span class="token string">&quot;&#39;&quot;</span>
    headers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;id&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;name&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;description&#39;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse_row</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> row<span class="token punctuation">)</span><span class="token punctuation">:</span>
        log<span class="token punctuation">.</span>msg<span class="token punctuation">(</span><span class="token string">&#39;Hi, this is a row!: %r&#39;</span> <span class="token operator">%</span> row<span class="token punctuation">)</span>

        item <span class="token operator">=</span> TestItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;id&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> row<span class="token punctuation">[</span><span class="token string">&#39;id&#39;</span><span class="token punctuation">]</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;name&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> row<span class="token punctuation">[</span><span class="token string">&#39;name&#39;</span><span class="token punctuation">]</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;description&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> row<span class="token punctuation">[</span><span class="token string">&#39;description&#39;</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> item
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,2),Ie={id:"_5-sitemapspider¶",tabindex:"-1"},Xe=s("a",{class:"header-anchor",href:"#_5-sitemapspider¶","aria-hidden":"true"},"#",-1),Ve={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#sitemapspider",target:"_blank",rel:"noopener noreferrer"},Te=s("em",null,"class",-1),Ue=s("code",null,"scrapy.contrib.spiders.SitemapSpider",-1),je={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.SitemapSpider",target:"_blank",rel:"noopener noreferrer"},De={href:"http://www.sitemaps.org/",target:"_blank",rel:"noopener noreferrer"},Oe={href:"http://www.robotstxt.org/",target:"_blank",rel:"noopener noreferrer"},Ee=s("code",null,"sitemap_urls",-1),Ae={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.SitemapSpider.sitemap_urls",target:"_blank",rel:"noopener noreferrer"},Pe={href:"http://www.robotstxt.org/",target:"_blank",rel:"noopener noreferrer"},Be=s("code",null,"sitemap_rules",-1),He={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.SitemapSpider.sitemap_rules",target:"_blank",rel:"noopener noreferrer"},Ye=t(`<p>一个包含 <code>(regex, callback)</code> 元组的列表(list):</p><ul><li><code>regex</code> 是一用于匹配从sitemap提供的url的正则表达式。 <code>regex</code> 可以是一个字符串或者编译的正则对象(compiled regex object)。</li><li>callback指定了匹配正则表达式的url的处理函数。 <code>callback</code> 可以是一个字符串(spider中方法的名字)或者是callable。</li></ul><p>例如:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>sitemap_rules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">&#39;/product/&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;parse_product&#39;</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>规则按顺序进行匹配，之后第一个匹配才会被应用。</p><p>如果您忽略该属性，sitemap中发现的所有url将会被 <code>parse</code> 函数处理。</p>`,6),Ge=s("code",null,"sitemap_follow",-1),Je={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.SitemapSpider.sitemap_follow",target:"_blank",rel:"noopener noreferrer"},Ke=s("p",null,"一个用于匹配要跟进的sitemap的正则表达式的列表(list)。其仅仅被应用在 使用 Sitemap index files 来指向其他sitemap文件的站点。",-1),Qe=s("p",null,"默认情况下所有的sitemap都会被跟进。",-1),We=s("code",null,"sitemap_alternate_links",-1),Ze={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#scrapy.contrib.spiders.SitemapSpider.sitemap_alternate_links",target:"_blank",rel:"noopener noreferrer"},$e=t(`<p>指定当一个 <code>url</code> 有可选的链接时，是否跟进。 有些非英文网站会在一个 <code>url</code> 块内提供其他语言的网站链接。</p><p>例如:</p><div class="language-html line-numbers-mode" data-ext="html"><pre class="language-html"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>url</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>loc</span><span class="token punctuation">&gt;</span></span>http://example.com/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>loc</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span><span class="token namespace">xhtml:</span>link</span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">&quot;</span>alternate<span class="token punctuation">&quot;</span></span> <span class="token attr-name">hreflang</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">&quot;</span>de<span class="token punctuation">&quot;</span></span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">&quot;</span>http://example.com/de<span class="token punctuation">&quot;</span></span><span class="token punctuation">/&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>url</span><span class="token punctuation">&gt;</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>当 <code>sitemap_alternate_links</code> 设置时，两个URL都会被获取。 当 <code>sitemap_alternate_links</code> 关闭时，只有 <code>http://example.com/</code> 会被获取。</p><p>默认 <code>sitemap_alternate_links</code> 关闭。</p>`,5),sa={id:"sitemapspider样例¶",tabindex:"-1"},na=s("a",{class:"header-anchor",href:"#sitemapspider样例¶","aria-hidden":"true"},"#",-1),ea={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#id7",target:"_blank",rel:"noopener noreferrer"},aa=t(`<p>简单的例子: 使用 <code>parse</code> 处理通过sitemap发现的所有url:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> SitemapSpider

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>SitemapSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sitemap_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;http://www.example.com/sitemap.xml&#39;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span> <span class="token comment"># ... scrape item here ...</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>用特定的函数处理某些url，其他的使用另外的callback:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> SitemapSpider

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>SitemapSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sitemap_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;http://www.example.com/sitemap.xml&#39;</span><span class="token punctuation">]</span>
    sitemap_rules <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">&#39;/product/&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;parse_product&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">&#39;/category/&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;parse_category&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse_product</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span> <span class="token comment"># ... scrape product ...</span>

    <span class="token keyword">def</span> <span class="token function">parse_category</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span> <span class="token comment"># ... scrape category ...</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4),ta={href:"http://www.robotstxt.org/",target:"_blank",rel:"noopener noreferrer"},pa=s("code",null,"..sitemap_shop",-1),oa=t(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> SitemapSpider

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>SitemapSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sitemap_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;http://www.example.com/robots.txt&#39;</span><span class="token punctuation">]</span>
    sitemap_rules <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">&#39;/shop/&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;parse_shop&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
    sitemap_follow <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;/sitemap_shops&#39;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse_shop</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span> <span class="token comment"># ... scrape shop here ...</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在SitemapSpider中使用其他url:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> SitemapSpider

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>SitemapSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sitemap_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;http://www.example.com/robots.txt&#39;</span><span class="token punctuation">]</span>
    sitemap_rules <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">&#39;/shop/&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;parse_shop&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

    other_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;http://www.example.com/about&#39;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        requests <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">super</span><span class="token punctuation">(</span>MySpider<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>start_requests<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        requests <span class="token operator">+=</span> <span class="token punctuation">[</span>scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse_other<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> self<span class="token punctuation">.</span>other_urls<span class="token punctuation">]</span>
        <span class="token keyword">return</span> requests

    <span class="token keyword">def</span> <span class="token function">parse_shop</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span> <span class="token comment"># ... scrape shop here ...</span>

    <span class="token keyword">def</span> <span class="token function">parse_other</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span> <span class="token comment"># ... scrape other here ...</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,3),ca={id:"讨论-¶",tabindex:"-1"},ra=s("a",{class:"header-anchor",href:"#讨论-¶","aria-hidden":"true"},"#",-1),ia={href:"https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html#discuss",target:"_blank",rel:"noopener noreferrer"};function la(da,ua){const e=o("ExternalLinkIcon");return c(),r("div",null,[s("p",null,[s("a",l,[n("https://scrapy-chs.readthedocs.io/zh_CN/latest/topics/spiders.html"),a(e)])]),d,u,s("ol",null,[h,s("li",null,[s("p",null,[n("在回调函数内，您可以使用 "),s("a",k,[n("选择器(Selectors)"),a(e)]),n(" (您也可以使用BeautifulSoup, lxml 或者您想用的任何解析器) 来分析网页内容，并根据分析的数据生成item。")])]),s("li",null,[s("p",null,[n("最后，由spider返回的item将被存到数据库(由某些 "),s("a",m,[n("Item Pipeline"),a(e)]),n(" 处理)或使用 "),s("a",_,[n("Feed exports"),a(e)]),n(" 存入到文件中。")])])]),v,s("h2",b,[y,n(" Spider参数"),s("a",g,[n("¶"),a(e)])]),f,s("p",null,[n("Spider参数也可以通过Scrapyd的 "),w,n(" API来传递。 参见 "),s("a",S,[n("Scrapyd documentation"),a(e)]),n(".")]),s("h2",C,[x,n(" 内置Spider参考手册"),s("a",N,[n("¶"),a(e)])]),s("p",null,[n("Scrapy提供多种方便的通用spider供您继承使用。 这些spider为一些常用的爬取情况提供方便的特性， 例如根据某些规则跟进某个网站的所有链接、根据 "),s("a",q,[n("Sitemaps"),a(e)]),n(" 来进行爬取，或者分析XML/CSV源。")]),z,s("h3",R,[M,n(" 1. Spider"),s("a",L,[n("¶"),a(e)])]),s("blockquote",null,[s("p",null,[F,n(),I,s("a",X,[n("¶"),a(e)])])]),V,s("blockquote",null,[s("p",null,[T,s("a",U,[n("¶"),a(e)])])]),j,s("p",null,[n("如果该spider爬取单个网站(single domain)，一个常见的做法是以该网站(domain)(加或不加 "),s("a",D,[n("后缀"),a(e)]),n(" )来命名spider。 例如，如果spider爬取 "),O,n(" ，该spider通常会被命名为 "),E,n(" 。")]),s("blockquote",null,[s("p",null,[A,s("a",P,[n("¶"),a(e)])])]),B,s("blockquote",null,[s("p",null,[H,s("a",Y,[n("¶"),a(e)])])]),G,s("blockquote",null,[s("p",null,[J,s("a",K,[n("¶"),a(e)])])]),Q,s("p",null,[n("For a list of available built-in settings see: "),s("a",W,[n("内置设定参考手册"),a(e)]),n(".")]),s("blockquote",null,[s("p",null,[Z,s("a",$,[n("¶"),a(e)])])]),ss,s("p",null,[n("Crawlers encapsulate a lot of components in the project for their single entry access (such as extensions, middlewares, signals managers, etc). See "),s("a",ns,[n("Crawler API"),a(e)]),n(" to know more about them.")]),s("blockquote",null,[s("p",null,[es,s("a",as,[n("¶"),a(e)])])]),s("p",null,[n("Configuration on which this spider is been ran. This is a "),ts,n(" instance, see the "),s("a",ps,[n("Settings"),a(e)]),n(" topic for a detailed introduction on this subject.")]),s("blockquote",null,[s("p",null,[os,n("("),cs,n(", *"),rs,n(", **"),is,n(")"),s("a",ls,[n("¶"),a(e)])])]),ds,us,hs,ks,s("ul",null,[ms,s("li",null,[_s,n(" ("),s("em",null,[s("a",vs,[n("list"),a(e)])]),n(") – arguments passed to the "),bs,n(" method")]),ys]),s("blockquote",null,[s("p",null,[gs,n("()"),s("a",fs,[n("¶"),a(e)])])]),ws,s("blockquote",null,[s("p",null,[Ss,n("("),Cs,n(")"),s("a",xs,[n("¶"),a(e)])])]),Ns,qs,s("blockquote",null,[s("p",null,[zs,n("("),Rs,n(")"),s("a",Ms,[n("¶"),a(e)])])]),Ls,s("blockquote",null,[s("p",null,[Fs,n("("),Is,n("[, "),Xs,n(", "),Vs,n("])"),s("a",Ts,[n("¶"),a(e)])])]),s("p",null,[n("使用 "),Us,n(" 方法记录(log)message。 log中自动带上该spider的 "),js,n(" 属性。 更多数据请参见 "),s("a",Ds,[n("Logging"),a(e)]),n(" 。")]),s("blockquote",null,[s("p",null,[Os,n("("),Es,n(")"),s("a",As,[n("¶"),a(e)])])]),Ps,s("h3",Bs,[Hs,n(" Spider样例"),s("a",Ys,[n("¶"),a(e)])]),Gs,s("h3",Js,[Ks,n(" 2. CrawlSpider"),s("a",Qs,[n("¶"),a(e)])]),s("blockquote",null,[s("p",null,[Ws,n(),Zs,s("a",$s,[n("¶"),a(e)])])]),sn,nn,s("p",null,[en,s("a",an,[n("¶"),a(e)])]),tn,pn,s("p",null,[on,n("("),cn,n(")"),s("a",rn,[n("¶"),a(e)])]),ln,s("h3",dn,[un,n(" 爬取规则(Crawling rules)"),s("a",hn,[n("¶"),a(e)])]),s("blockquote",null,[s("p",null,[kn,n(),mn,n("(link_"),_n,n(", "),vn,n(", cb_"),bn,n(", "),yn,n(", process_"),gn,n(", process_"),fn,n(")"),s("a",wn,[n("¶"),a(e)])])]),s("p",null,[Sn,n(" 是一个 "),s("a",Cn,[n("Link Extractor"),a(e)]),n(" 对象。 其定义了如何从爬取到的页面提取链接。")]),xn,s("h3",Nn,[qn,n(" CrawlSpider样例"),s("a",zn,[n("¶"),a(e)])]),Rn,s("h3",Mn,[Ln,n(" 3. XMLFeedSpider"),s("a",Fn,[n("¶"),a(e)])]),s("blockquote",null,[s("p",null,[In,n(),Xn,s("a",Vn,[n("¶"),a(e)])])]),Tn,s("p",null,[Un,s("a",jn,[n("¶"),a(e)])]),Dn,s("p",null,[On,s("a",En,[n("¶"),a(e)])]),An,s("p",null,[Pn,s("a",Bn,[n("¶"),a(e)])]),Hn,s("p",null,[Yn,n("("),Gn,n(")"),s("a",Jn,[n("¶"),a(e)])]),Kn,s("p",null,[Qn,n("("),Wn,n(", "),Zn,n(")"),s("a",$n,[n("¶"),a(e)])]),se,s("p",null,[ne,n("("),ee,n(", "),ae,n(")"),s("a",te,[n("¶"),a(e)])]),pe,s("h3",oe,[ce,n(" XMLFeedSpider例子"),s("a",re,[n("¶"),a(e)])]),ie,s("h3",le,[de,n(" 4. CSVFeedSpider"),s("a",ue,[n("¶"),a(e)])]),s("blockquote",null,[s("p",null,[he,n(),ke,s("a",me,[n("¶"),a(e)])])]),_e,s("p",null,[ve,s("a",be,[n("¶"),a(e)])]),ye,s("p",null,[ge,s("a",fe,[n("¶"),a(e)])]),we,Se,s("p",null,[Ce,n("("),xe,n(", "),Ne,n(")"),s("a",qe,[n("¶"),a(e)])]),ze,s("h3",Re,[Me,n(" CSVFeedSpider例子"),s("a",Le,[n("¶"),a(e)])]),Fe,s("h3",Ie,[Xe,n(" 5. SitemapSpider"),s("a",Ve,[n("¶"),a(e)])]),s("blockquote",null,[s("p",null,[Te,n(),Ue,s("a",je,[n("¶"),a(e)])])]),s("p",null,[n("SitemapSpider使您爬取网站时可以通过 "),s("a",De,[n("Sitemaps"),a(e)]),n(" 来发现爬取的URL。")]),s("p",null,[n("其支持嵌套的sitemap，并能从 "),s("a",Oe,[n("robots.txt"),a(e)]),n(" 中获取sitemap的url。")]),s("p",null,[Ee,s("a",Ae,[n("¶"),a(e)])]),s("p",null,[n("包含您要爬取的url的sitemap的url列表(list)。 您也可以指定为一个 "),s("a",Pe,[n("robots.txt"),a(e)]),n(" ，spider会从中分析并提取url。")]),s("p",null,[Be,s("a",He,[n("¶"),a(e)])]),Ye,s("p",null,[Ge,s("a",Je,[n("¶"),a(e)])]),Ke,Qe,s("p",null,[We,s("a",Ze,[n("¶"),a(e)])]),$e,s("h3",sa,[na,n(" SitemapSpider样例"),s("a",ea,[n("¶"),a(e)])]),aa,s("p",null,[n("跟进 "),s("a",ta,[n("robots.txt"),a(e)]),n(" 文件定义的sitemap并只跟进包含有 "),pa,n(" 的url:")]),oa,s("h2",ca,[ra,n(" 讨论 "),s("a",ia,[n("¶"),a(e)])])])}const ma=p(i,[["render",la],["__file","Spiders.html.vue"]]);export{ma as default};
